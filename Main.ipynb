{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from cheak_tools import cheak_type, cheak_interval, cheak_range\n",
    "# see Cheak_tools.ipynb in https://github.com/Dogiko/Some-Tools/\n",
    "\n",
    "from torch_refiner import LinearRefiner\n",
    "# see https://github.com/Dogiko/Linear-Refiner\n",
    "\n",
    "from torch_expander import LinearExpander\n",
    "# see https://github.com/Dogiko/Layer-Expander\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FCNet(torch.nn.Module):\n",
    "    def __init__(self, architecture, activation_function = torch.tanh):\n",
    "        super(FCNet, self).__init__()\n",
    "        \n",
    "        for l in range(len(architecture) - 1):\n",
    "            cheak_range(architecture[l], 1)\n",
    "        \n",
    "        self.fc_modules = torch.nn.ModuleList()\n",
    "        for l in range(len(architecture) - 1):\n",
    "            self.fc_modules.append(torch.nn.Linear(architecture[l], architecture[l+1]))\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def get_layers_num(self):\n",
    "        return (len(self.fc_modules))\n",
    "    \n",
    "    def get_architecture(self):\n",
    "        output = ()\n",
    "        for l in range(self.get_layers_num()):\n",
    "            output += (self.fc_modules[l].in_features, )\n",
    "        \n",
    "        output += (self.fc_modules[-1].out_features, )\n",
    "        return output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in range(self.get_layers_num() - 1):\n",
    "            x = self.fc_modules[l](x)\n",
    "            x = self.activation_function(x)\n",
    "        \n",
    "        x = self.fc_modules[-1](x)\n",
    "        return x\n",
    "    \n",
    "    def partial_forward(self, x, hidden_layer_idx):\n",
    "        for l in range(hidden_layer_idx+1):\n",
    "            x = self.fc_modules[l](x)\n",
    "            x = self.activation_function(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class DoTorch():\n",
    "    def __init__(self):\n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "        self.tests_loader = None # tests : using five words, same as train and valid\n",
    "        self.net = None\n",
    "        self.optimizer = None\n",
    "        self.criterion = None\n",
    "        self.record = None\n",
    "        self.lr_multi = 0.1\n",
    "    \n",
    "    def set_train_loader(self, train_loader):\n",
    "        cheak_type(train_loader, utils.dataloader.DataLoader)\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "    \n",
    "    def set_valid_loader(self, valid_loader):\n",
    "        cheak_type(valid_loader, utils.dataloader.DataLoader)\n",
    "        \n",
    "        self.valid_loader = valid_loader\n",
    "    \n",
    "    def set_tests_loader(self, tests_loader):\n",
    "        cheak_type(tests_loader, utils.dataloader.DataLoader)\n",
    "        \n",
    "        self.tests_loader = tests_loader\n",
    "    \n",
    "    def set_data(self, train_data, valid_data = None, tests_data = None, batch_size=1, shuffle=True, drop_last=True):\n",
    "        cheak_type(train_data, utils.dataset.TensorDataset)\n",
    "        cheak_type(valid_data, (utils.dataset.TensorDataset, type(None), float))\n",
    "        cheak_type(tests_data, (utils.dataset.TensorDataset, type(None)))\n",
    "        cheak_range(batch_size, mini=1)\n",
    "        \n",
    "        if valid_data is not None:\n",
    "            try:\n",
    "                cheak_interval(valid_data, 0, 1)\n",
    "                # if valid_data is a ratio (0~1), get valid_data from part of train_data\n",
    "                valid_len = max(1, int(len(train_data)*valid_data))\n",
    "                split_data = utils.dataset.random_split(train_data, [len(train_data)-valid_len, valid_len])\n",
    "                train_data = split_data[0]\n",
    "                valid_data = split_data[1]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            self.set_valid_loader(utils.DataLoader(valid_data, batch_size=min(batch_size, len(valid_data)),\n",
    "                                                   shuffle=shuffle, drop_last=drop_last))\n",
    "        \n",
    "        self.set_train_loader(utils.DataLoader(train_data, batch_size=min(batch_size, len(train_data)),\n",
    "                                               shuffle=shuffle, drop_last=drop_last))\n",
    "        if tests_data is not None:\n",
    "            self.set_tests_loader(utils.DataLoader(tests_data, batch_size=min(batch_size, len(tests_data)),\n",
    "                                                   shuffle=shuffle, drop_last=drop_last))\n",
    "    \n",
    "    def set_net(self, net):\n",
    "        cheak_type(net, torch.nn.Module)\n",
    "        \n",
    "        self.net = net\n",
    "    \n",
    "    def set_criterion(self, criterion):\n",
    "        cheak_type(criterion, torch.nn.Module)\n",
    "        \n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def set_optimizer(self, optimizer):\n",
    "        cheak_type(optimizer, torch.optim.Optimizer)\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def one_step(self, _input, labels):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(self.net(_input), labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.data\n",
    "    \n",
    "    def epoch_fit(self, loss_detail=False):\n",
    "        loss_record = torch.zeros([len(self.train_loader)])\n",
    "        for b, data in enumerate(self.train_loader):\n",
    "            _input, labels = data\n",
    "            loss_record[b] = self.one_step(_input, labels)\n",
    "        \n",
    "        if loss_detail:\n",
    "            return loss_record\n",
    "        else:\n",
    "            return loss_record.mean()\n",
    "    \n",
    "    def evaluate(self, batchs = None):\n",
    "        if batchs is None:\n",
    "            batchs = len(self.valid_loader)\n",
    "        \n",
    "        cheak_range(batchs, 1)\n",
    "        \n",
    "        loss_record = []\n",
    "        for b, data in enumerate(self.valid_loader):\n",
    "            _input, labels = data\n",
    "            loss_record.append(self.criterion(self.net(_input), labels))\n",
    "            if b == batchs-1:\n",
    "                break\n",
    "        \n",
    "        return torch.tensor(loss_record).mean()\n",
    "    \n",
    "    def test(self, batchs = None):\n",
    "        if batchs is None:\n",
    "            batchs = len(self.tests_loader)\n",
    "        \n",
    "        cheak_range(batchs, 1)\n",
    "        \n",
    "        loss_record = []\n",
    "        for b, data in enumerate(self.tests_loader):\n",
    "            _input, labels = data\n",
    "            loss_record.append(self.criterion(self.net(_input), labels))\n",
    "            if b == batchs-1:\n",
    "                break\n",
    "        \n",
    "        return torch.tensor(loss_record).mean()\n",
    "        \n",
    "    \n",
    "    def fit(self, epochs, loss_detail=False):\n",
    "        cheak_interval(epochs, 1) # epochs should be an positive int\n",
    "        \n",
    "        loss = {}\n",
    "        if loss_detail:\n",
    "            loss[\"train\"] = torch.zeros([epochs, len(self.train_loader)])\n",
    "        else:\n",
    "            loss[\"train\"] = torch.zeros([epochs])\n",
    "        \n",
    "        if self.valid_loader is not None:\n",
    "            loss[\"valid\"] = torch.zeros([epochs])\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            loss[\"train\"][e] = self.epoch_fit(loss_detail=loss_detail)\n",
    "            if self.valid_loader is not None:\n",
    "                loss[\"valid\"][e] = self.evaluate()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def set_lr_multi(self, _input):\n",
    "        cheak_interval(_input, mini=0.)\n",
    "        \n",
    "        self.lr_multi = _input\n",
    "    \n",
    "    def neuron_refine(self, layer_idx, drop=1, threshold=0.001, collinear_cut=None,\n",
    "                      quick=True, data_set=\"t\", lr_multi = None):\n",
    "        cheak_range(layer_idx, mini=0, maxi=self.net.get_layers_num()-2)\n",
    "        \n",
    "        if lr_multi == None:\n",
    "            lr_multi = self.lr_multi\n",
    "        \n",
    "        li=layer_idx\n",
    "        refiner = LinearRefiner(self.net.fc_modules[li+1])\n",
    "        refiner.reset()\n",
    "        if data_set == \"t\":\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "                _input, _ = data\n",
    "                refiner.data_input(self.net.partial_forward(_input, layer_idx).data)\n",
    "        elif data_set == \"v\":\n",
    "            for i, data in enumerate(self.valid_loader):\n",
    "                _input, _ = data\n",
    "                refiner.data_input(self.net.partial_forward(_input, layer_idx).data)\n",
    "        else:\n",
    "            raise ValueError(\"data_set error, except 't'(train) or 'v'(valid), got %s\" %(data_set))\n",
    "        \n",
    "        if collinear_cut is None:\n",
    "            result = refiner.refine(drop, quick)\n",
    "        else:\n",
    "            result, _ = refiner.collinear_cut(method=collinear_cut, threshold=threshold,\n",
    "                                              quick=quick, drop_limit=drop)\n",
    "        \n",
    "        remain_idx, out_weight, out_bias, _, _ = result\n",
    "        in_weight = self.net.fc_modules[li].weight.data[remain_idx]\n",
    "        in_bias = self.net.fc_modules[li].bias.data[remain_idx]\n",
    "        self.net.fc_modules[li] = torch.nn.Linear(in_weight.shape[1], in_weight.shape[0])\n",
    "        self.net.fc_modules[li].weight.data = in_weight\n",
    "        self.net.fc_modules[li].bias.data = in_bias\n",
    "        self.net.fc_modules[li+1] = torch.nn.Linear(out_weight.shape[1], out_weight.shape[0])\n",
    "        self.net.fc_modules[li+1].weight.data = out_weight\n",
    "        self.net.fc_modules[li+1].bias.data = out_bias\n",
    "        new_optim = type(self.optimizer)(self.net.parameters())\n",
    "        new_optim.defaults.update(self.optimizer.defaults)\n",
    "        new_optim.param_groups[0].update(self.optimizer.defaults)\n",
    "        new_optim.param_groups[0]['lr'] *= lr_multi\n",
    "        self.set_optimizer(new_optim)\n",
    "    \n",
    "    def neuron_hyperplasia(self, layer_idx, _add=1, candidate_num=None, weighted=True,\n",
    "                           std=None, epsilon=0., lr_multi = None):\n",
    "        cheak_range(layer_idx, mini=0, maxi=self.net.get_layers_num()-2)\n",
    "        cheak_interval(epsilon, mini=0., left_close=True)\n",
    "        \n",
    "        if lr_multi == None:\n",
    "            lr_multi = self.lr_multi\n",
    "        \n",
    "        if candidate_num is None:\n",
    "            candidate_num = _add\n",
    "            weighted = False\n",
    "        \n",
    "        li=layer_idx\n",
    "        \n",
    "        ori_out_weight = self.net.fc_modules[li+1].weight.data\n",
    "        ori_out_bias = self.net.fc_modules[li+1].bias.data\n",
    "        \n",
    "        in_features = self.net.fc_modules[li].in_features\n",
    "        ori_features = self.net.fc_modules[li].out_features\n",
    "        out_features = self.net.fc_modules[li+1].out_features\n",
    "        \n",
    "        if std is None:\n",
    "            std = np.sqrt(1/(3*(ori_features + _add)))\n",
    "        \n",
    "        linear_expander = LinearExpander(self.net.fc_modules[li], self.net.activation_function,\n",
    "                                         candidate_num, std=std)\n",
    "        if weighted:\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "                _input, _ = data\n",
    "                linear_expander.data_input(self.net.partial_forward(_input, li-1))\n",
    "        \n",
    "        self.net.fc_modules[li] = linear_expander.expand(_add, weighted)\n",
    "        \n",
    "        self.net.fc_modules[li+1] = torch.nn.Linear(ori_features+_add, out_features)\n",
    "        self.net.fc_modules[li+1].weight.data[:, :ori_features] = ori_out_weight\n",
    "        self.net.fc_modules[li+1].weight.data[:, ori_features:] *= epsilon\n",
    "        self.net.fc_modules[li+1].bias.data = ori_out_bias\n",
    "        \n",
    "        new_optim = type(self.optimizer)(self.net.parameters())\n",
    "        new_optim.defaults.update(self.optimizer.defaults)\n",
    "        new_optim.param_groups[0].update(self.optimizer.defaults)\n",
    "        new_optim.param_groups[0]['lr'] *= lr_multi\n",
    "        self.set_optimizer(new_optim)\n",
    "    \n",
    "    def neuron_adjust(self, layer_idx, neuron_num, quick=True, data_set=\"t\", epsilon=0., lr_multi=None):\n",
    "        cheak_range(layer_idx, mini=0, maxi=self.net.get_layers_num()-2)\n",
    "        cheak_range(neuron_num, mini=1)\n",
    "        \n",
    "        exceed = neuron_num - self.net.get_architecture()[layer_idx+1]\n",
    "        if exceed>0:\n",
    "            self.neuron_hyperplasia(layer_idx=layer_idx, _add=exceed, epsilon=epsilon)\n",
    "        elif exceed<0:\n",
    "            self.neuron_refine(layer_idx=layer_idx, drop=-exceed, quick=quick, data_set=data_set, lr_multi=lr_multi)\n",
    "    \n",
    "    def architecture_adjust(self, layers, neurons, quick=True, data_set=\"t\", epsilon=0., lr_multi=None):\n",
    "        layer_iter = iter(layers)\n",
    "        neuron_iter = iter(neurons)\n",
    "        while True:\n",
    "            try:\n",
    "                li = next(layer_iter)\n",
    "                n = next(neuron_iter)\n",
    "            except:\n",
    "                break\n",
    "            \n",
    "            self.neuron_adjust(layer_idx=li, neuron_num=n, quick=quick, data_set=data_set\n",
    "                               , epsilon=epsilon, lr_multi=lr_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple case\n",
    "\n",
    "odd or even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = DoTorch()\n",
    "\n",
    "x = np.arange(600)-299\n",
    "x = x/100\n",
    "y = np.zeros((600))\n",
    "y[:] = 1* (np.ceil(x) %2)\n",
    "x = x.reshape(600,1)\n",
    "x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "y = Variable(torch.from_numpy(y).type(torch.LongTensor))\n",
    "train = utils.TensorDataset(x, y)\n",
    "\n",
    "foo.set_net(FCNet((1,5,2)))\n",
    "foo.set_data(train_data=train, valid_data=0.1, batch_size=60)\n",
    "foo.set_criterion(torch.nn.CrossEntropyLoss())\n",
    "foo.set_optimizer(torch.optim.Adam(foo.net.parameters(), lr = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10add8080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/fbnwbMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1091716a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "record = foo.fit(200)\n",
    "\n",
    "plt.plot(range(len(record['valid'].data)), record['train'].data.numpy(), \"r\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x.data.numpy().reshape(-1), torch.nn.Softmax()(foo.net(x)).data.numpy()[:,0], \"bp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find suitable architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 2) tensor(0.4266)\n",
      "(1, 5, 2) tensor(0.0520)\n",
      "(1, 5, 2) tensor(0.0311)\n",
      "(1, 5, 2) tensor(0.0263)\n",
      "(1, 5, 2) tensor(0.0260)\n"
     ]
    }
   ],
   "source": [
    "foo = DoTorch()\n",
    "\n",
    "x = np.arange(600)-299\n",
    "x = x/100\n",
    "y = np.zeros((600))\n",
    "y[:] = 1* (np.ceil(x) %2)\n",
    "x = x.reshape(600,1)\n",
    "x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "y = Variable(torch.from_numpy(y).type(torch.LongTensor))\n",
    "train = utils.TensorDataset(x, y)\n",
    "\n",
    "foo.set_net(FCNet((1,1,2)))\n",
    "foo.set_data(train_data=train, valid_data=0.1, batch_size=60)\n",
    "foo.set_criterion(torch.nn.CrossEntropyLoss())\n",
    "foo.set_optimizer(torch.optim.Adam(foo.net.parameters(), lr = 0.1))\n",
    "\n",
    "foo.fit(100)\n",
    "\n",
    "for t in range(5):\n",
    "    foo.neuron_hyperplasia(0, 5, candidate_num=10)\n",
    "    foo.fit(100)\n",
    "    foo.neuron_refine(0, drop=6, collinear_cut='vr')\n",
    "    print(foo.net.get_architecture(), foo.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 5, 10) tensor(0.5054)\n",
      "tensor(0.8555)\n",
      "(784, 5, 10) tensor(0.4955)\n",
      "tensor(0.8585)\n",
      "(784, 5, 10) tensor(0.4752)\n",
      "tensor(0.8623)\n",
      "(784, 5, 10) tensor(0.4641)\n",
      "tensor(0.8663)\n",
      "(784, 5, 10) tensor(0.4552)\n",
      "tensor(0.8658)\n"
     ]
    }
   ],
   "source": [
    "foo = DoTorch()\n",
    "\n",
    "x = np.load('../mnist-npy/train_data.npy')/255\n",
    "x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "y = np.load('../mnist-npy/train_label.npy').argmax(axis=1)\n",
    "y = Variable(torch.from_numpy(y).type(torch.LongTensor))\n",
    "train = utils.TensorDataset(x, y)\n",
    "\n",
    "x = np.load('../mnist-npy/test_data.npy')/255\n",
    "x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "y = np.load('../mnist-npy/test_label.npy').argmax(axis=1)\n",
    "y = Variable(torch.from_numpy(y).type(torch.LongTensor))\n",
    "test = utils.TensorDataset(x, y)\n",
    "\n",
    "foo.set_net(FCNet((784,5,10)))\n",
    "foo.set_data(train_data=train, valid_data=0.1, tests_data=test, batch_size=6000)\n",
    "foo.set_criterion(torch.nn.CrossEntropyLoss())\n",
    "foo.set_optimizer(torch.optim.Adam(foo.net.parameters(), lr = 0.01, betas=(0.9, 0.999)))\n",
    "\n",
    "foo.fit(50)\n",
    "\n",
    "for t in range(5):\n",
    "    foo.neuron_hyperplasia(0, 5, candidate_num=10)\n",
    "    foo.fit(50)\n",
    "    foo.neuron_refine(0, 5, data_set=\"v\")\n",
    "    print(foo.net.get_architecture(), foo.evaluate())\n",
    "    \n",
    "    datums = 0.\n",
    "    hit = 0.\n",
    "    for b, data in enumerate(foo.tests_loader):\n",
    "        _input, labels = data\n",
    "        datums += _input.size()[0]\n",
    "        hit += (foo.net(_input).data.max(1)[1] == labels).sum()\n",
    "\n",
    "    print(hit.type(torch.FloatTensor)/datums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9243)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datums = 0.\n",
    "hit = 0.\n",
    "for b, data in enumerate(foo.tests_loader):\n",
    "    _input, labels = data\n",
    "    datums += _input.size()[0]\n",
    "    hit += (foo.net(_input).data.max(1)[1] == labels).sum()\n",
    "\n",
    "hit.type(torch.FloatTensor)/datums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47372)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
